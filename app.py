import streamlit as st
import os
import tempfile
import datetime
import google.generativeai as genai
from openai import OpenAI

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(page_title="AIè­°äº‹éŒ²Pro", page_icon="ğŸ“")

st.title("ğŸ“ AIçµ±åˆãƒ¬ãƒãƒ¼ãƒˆä½œæˆãƒ„ãƒ¼ãƒ«")
st.caption("æ™‚ç³»åˆ—é †ã«çµåˆã—ã¦1ã¤ã®ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¾ã™")

# --- ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆåˆæœŸåŒ–ï¼ˆçµæœã®ä¸€æ™‚ä¿å­˜ç”¨ï¼‰ ---
if "report_text" not in st.session_state:
    st.session_state.report_text = None
if "full_transcript" not in st.session_state:
    st.session_state.full_transcript = None
if "file_names" not in st.session_state:
    st.session_state.file_names = []

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼šè¨­å®š ---
with st.sidebar:
    st.header("ğŸ”‘ è¨­å®š")
    openai_key = st.text_input("OpenAI API Key (sk-...)", type="password")
    gemini_key = st.text_input("Gemini API Key (AIza...)", type="password")
    
    st.divider()
    
    # ãƒ¬ãƒãƒ¼ãƒˆç¨®é¡ã®é¸æŠ
    report_type = st.radio(
        "ğŸ“„ ãƒ¬ãƒãƒ¼ãƒˆã®ç¨®é¡",
        ["ä¼šè­°ãƒ»æ‰“ã¡åˆã‚ã›", "è¬›æ¼”ä¼šãƒ»ã‚»ãƒŸãƒŠãƒ¼", "ç›¸è«‡ä¼šãƒ»ãƒ’ã‚¢ãƒªãƒ³ã‚°"],
        index=0
    )
    
    st.divider()
    
    # ã€å¤‰æ›´ç‚¹ã€‘ãƒ¢ãƒ‡ãƒ«é¸æŠï¼ˆæ‰‹å‹•é¸æŠã§ gemini-pro ã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã«ã™ã‚‹ï¼‰
    st.header("âš™ï¸ ãƒ¢ãƒ‡ãƒ«è¨­å®š")
    model_options = ["gemini-pro", "gemini-1.5-flash", "gemini-1.5-pro"]
    selected_model = st.selectbox(
        "ä½¿ç”¨ãƒ¢ãƒ‡ãƒ« (ã‚¨ãƒ©ãƒ¼æ™‚ã¯ gemini-pro ã‚’æ¨å¥¨)", 
        model_options, 
        index=0  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’ gemini-pro ã«è¨­å®šï¼ˆä¸€ç•ªå®‰å®šã—ã¦ã„ã‚‹ãŸã‚ï¼‰
    )
    
    st.divider()
    # ãƒªã‚»ãƒƒãƒˆãƒœã‚¿ãƒ³
    if st.button("ğŸ—‘ï¸ å±¥æ­´ã‚’ã‚¯ãƒªã‚¢ã—ã¦ãƒªã‚»ãƒƒãƒˆ"):
        st.session_state.report_text = None
        st.session_state.full_transcript = None
        st.session_state.file_names = []
        st.rerun()

# --- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå®šç¾© ---
prompts = {
    "ä¼šè­°ãƒ»æ‰“ã¡åˆã‚ã›": """
    ã‚ãªãŸã¯å„ªç§€ãªæ›¸è¨˜ã§ã™ã€‚ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã¯ã€Œä¼šè­°ã€ã®éŒ²éŸ³ã§ã™ã€‚
    è¤‡æ•°ã®éŒ²éŸ³ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ™‚ç³»åˆ—ã«çµåˆã—ã¦ã„ã¾ã™ã€‚å†…å®¹ã‚’çµ±åˆã—ã€ä»¥ä¸‹ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§Markdownãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
    
    # {date} ä¼šè­°è­°äº‹éŒ²
    
    ## 1. ä¼šè­°ã®æ¦‚è¦
    ï¼ˆ3è¡Œç¨‹åº¦ã§è¦ç´„ï¼‰
    
    ## 2. æ±ºå®šäº‹é …
    - 
    
    ## 3. è­°è«–ã®å†…å®¹ï¼ˆè©³ç´°ï¼‰
    - 
    
    ## 4. ãƒã‚¯ã‚¹ãƒˆã‚¢ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆToDoï¼‰
    - [æ‹…å½“] æœŸé™: ã‚¿ã‚¹ã‚¯å†…å®¹
    """,
    
    "è¬›æ¼”ä¼šãƒ»ã‚»ãƒŸãƒŠãƒ¼": """
    ã‚ãªãŸã¯å„ªç§€ãªãƒ©ã‚¤ã‚¿ãƒ¼ã§ã™ã€‚ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã¯ã€Œè¬›æ¼”ä¼šã€ã®éŒ²éŸ³ã§ã™ã€‚
    èãæ‰‹ãŒå†…å®¹ã‚’æ·±ãç†è§£ã§ãã‚‹ã‚ˆã†ã€ä»¥ä¸‹ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§è¬›ç¾©éŒ²ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
    
    # {date} è¬›æ¼”ãƒ¬ãƒãƒ¼ãƒˆ
    
    ## 1. è¬›æ¼”ã®ãƒ†ãƒ¼ãƒã¨è¦æ—¨
    
    ## 2. ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆï¼ˆå­¦ã³ï¼‰
    - **ãƒã‚¤ãƒ³ãƒˆ1**: è©³ç´°...
    - **ãƒã‚¤ãƒ³ãƒˆ2**: è©³ç´°...
    
    ## 3. è¬›ç¾©ã®è©³ç´°æ§‹æˆï¼ˆãƒã‚¤ãƒ³ãƒ‰ãƒãƒƒãƒ—é¢¨ï¼‰
    
    ## 4. è³ªç–‘å¿œç­”ã®è¦ç‚¹
    """,
    
    "ç›¸è«‡ä¼šãƒ»ãƒ’ã‚¢ãƒªãƒ³ã‚°": """
    ã‚ãªãŸã¯è¡Œæ”¿æ›¸å£«ãªã©ã®å°‚é–€å®¶ã®ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã¯ã€Œç›¸è«‡ä¼šã€ã®éŒ²éŸ³ã§ã™ã€‚
    ç›¸è«‡è€…ã®æ‚©ã¿ã¨ã€ãã‚Œã«å¯¾ã™ã‚‹å›ç­”ã‚’æ•´ç†ã—ã¦ãã ã•ã„ã€‚
    
    # {date} ç›¸è«‡è¨˜éŒ²
    
    ## 1. ç›¸è«‡è€…ã®å±æ€§ãƒ»çŠ¶æ³
    
    ## 2. ç›¸è«‡å†…å®¹ï¼ˆæ‚©ã¿ãƒ»èª²é¡Œï¼‰
    
    ## 3. å°‚é–€å®¶ã‹ã‚‰ã®å›ç­”ãƒ»ã‚¢ãƒ‰ãƒã‚¤ã‚¹
    
    ## 4. ä»Šå¾Œã®å¯¾å¿œæ–¹é‡ãƒ»æ‰‹ç¶šã
    """
}

# --- ãƒ¡ã‚¤ãƒ³å‡¦ç† ---
uploaded_files = st.file_uploader(
    "éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆè‡ªå‹•ã§ãƒ•ã‚¡ã‚¤ãƒ«åé †ã«ä¸¦ã³æ›¿ãˆã¾ã™ï¼‰", 
    type=["mp3", "m4a", "wav"], 
    accept_multiple_files=True
)

if uploaded_files and openai_key and gemini_key:
    # ãƒ•ã‚¡ã‚¤ãƒ«åã§ã‚½ãƒ¼ãƒˆ
    uploaded_files.sort(key=lambda x: x.name)
    current_file_names = [f.name for f in uploaded_files]
    
    # ãƒ•ã‚¡ã‚¤ãƒ«åãŒå¤‰ã‚ã£ãŸã‚‰ãƒªã‚»ãƒƒãƒˆã™ã‚‹ãƒ­ã‚¸ãƒƒã‚¯ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    if st.session_state.file_names and st.session_state.file_names != current_file_names:
        st.warning("âš ï¸ æ–°ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«ãŒé¸æŠã•ã‚Œã¾ã—ãŸã€‚ã€Œå±¥æ­´ã‚’ã‚¯ãƒªã‚¢ã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ãƒªã‚»ãƒƒãƒˆã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚")

    # å‡¦ç†å®Ÿè¡Œãƒœã‚¿ãƒ³
    if st.button("ğŸš€ ãƒ¬ãƒãƒ¼ãƒˆä½œæˆã‚’é–‹å§‹"):
        # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        client = OpenAI(api_key=openai_key)
        genai.configure(api_key=gemini_key)
        model = genai.GenerativeModel(selected_model)
        
        full_transcript = ""
        
        # 1. æ–‡å­—èµ·ã“ã—ãƒ«ãƒ¼ãƒ—
        for i, uploaded_file in enumerate(uploaded_files):
            try:
                status_text.text(f"æ–‡å­—èµ·ã“ã—ä¸­ ({i+1}/{len(uploaded_files)}): {uploaded_file.name}")
                
                with tempfile.NamedTemporaryFile(delete=False, suffix=f".{uploaded_file.name.split('.')[-1]}") as tmp_file:
                    tmp_file.write(uploaded_file.getvalue())
                    tmp_file_path = tmp_file.name
                
                with open(tmp_file_path, "rb") as audio_file:
                    transcript = client.audio.transcriptions.create(
                        model="whisper-1", 
                        file=audio_file,
                        response_format="text"
                    )
                
                os.remove(tmp_file_path)
                
                full_transcript += f"\n\n--- éŒ²éŸ³ãƒ‡ãƒ¼ã‚¿: {uploaded_file.name} ---\n\n"
                full_transcript += transcript
                
                progress_bar.progress((i + 1) / (len(uploaded_files) + 1))
                
            except Exception as e:
                st.error(f"æ–‡å­—èµ·ã“ã—ã‚¨ãƒ©ãƒ¼ ({uploaded_file.name}): {e}")
                st.stop()

        # 2. ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ
        status_text.text(f"ğŸ§  AI({selected_model})ãŒãƒ¬ãƒãƒ¼ãƒˆã‚’åŸ·ç­†ä¸­...")
        
        today_str = datetime.date.today().strftime('%Y-%m-%d')
        prompt_template = prompts[report_type].format(date=today_str)
        final_prompt = f"{prompt_template}\n\nã€ä»¥ä¸‹ã®çµåˆãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚‚ã¨ã«ä½œæˆã—ã¦ãã ã•ã„ã€‘\n{full_transcript}"
        
        try:
            response = model.generate_content(final_prompt)
            
            # çµæœã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã«ä¿å­˜
            st.session_state.report_text = response.text
            st.session_state.full_transcript = full_transcript
            st.session_state.file_names = current_file_names
            
            progress_bar.progress(100)
            status_text.success("å®Œäº†ã—ã¾ã—ãŸï¼")
            
        except Exception as e:
            st.error(f"ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            st.error("ãƒ’ãƒ³ãƒˆ: å·¦å´ã®è¨­å®šã§ãƒ¢ãƒ‡ãƒ«ã‚’ã€Œgemini-proã€ã«å¤‰æ›´ã—ã¦å†è©¦è¡Œã—ã¦ãã ã•ã„ã€‚")

# --- ä¿å­˜ã•ã‚ŒãŸçµæœãŒã‚ã‚Œã°è¡¨ç¤º ---
if st.session_state.report_text:
    st.divider()
    st.subheader(f"ğŸ“Š {report_type} ãƒ¬ãƒãƒ¼ãƒˆ")
    
    st.markdown(st.session_state.report_text)
    
    # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«åä½œæˆ
    today_str = datetime.date.today().strftime('%Y-%m-%d')
    file_name_candidate = f"{today_str}_report"
    for line in st.session_state.report_text.split('\n'):
        if line.startswith("# "):
            file_name_candidate = line.replace("# ", "").strip().replace(" ", "_").replace("/", "-")
            break
            
    st.download_button(
        label="ğŸ’¾ ãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜ (mdãƒ•ã‚¡ã‚¤ãƒ«)",
        data=st.session_state.report_text,
        file_name=f"{file_name_candidate}.md",
        mime="text/markdown"
    )
    
    with st.expander("æ–‡å­—èµ·ã“ã—åŸæ–‡ï¼ˆçµåˆç‰ˆï¼‰ã‚’ç¢ºèªã™ã‚‹"):
        st.text_area("åŸæ–‡", st.session_state.full_transcript, height=200)

elif not (openai_key and gemini_key):
    st.warning("ğŸ‘ˆ å·¦ã®ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
