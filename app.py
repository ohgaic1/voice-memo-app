import streamlit as st
import os
import tempfile
import datetime
import re
from openai import OpenAI
import google.generativeai as genai

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(page_title="AIè­°äº‹éŒ²Pro", page_icon="ğŸ“")

st.title("ğŸ“ AIçµ±åˆãƒ¬ãƒãƒ¼ãƒˆä½œæˆãƒ„ãƒ¼ãƒ«")
st.caption("æ™‚ç³»åˆ—é †ã«çµåˆã—ã¦1ã¤ã®ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¾ã™")

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼šè¨­å®š ---
with st.sidebar:
    st.header("ğŸ”‘ è¨­å®š")
    openai_key = st.text_input("OpenAI API Key (sk-...)", type="password")
    gemini_key = st.text_input("Gemini API Key (AIza...)", type="password")
    
    st.divider()
    
    # ãƒ¬ãƒãƒ¼ãƒˆç¨®é¡ã®é¸æŠ
    report_type = st.radio(
        "ğŸ“„ ãƒ¬ãƒãƒ¼ãƒˆã®ç¨®é¡",
        ["ä¼šè­°ãƒ»æ‰“ã¡åˆã‚ã›", "è¬›æ¼”ä¼šãƒ»ã‚»ãƒŸãƒŠãƒ¼", "ç›¸è«‡ä¼šãƒ»ãƒ’ã‚¢ãƒªãƒ³ã‚°"],
        index=0
    )
    
    st.divider()
    
    # ãƒ¢ãƒ‡ãƒ«é¸æŠ (è‡ªå‹•å–å¾—ãƒ­ã‚¸ãƒƒã‚¯)
    available_models = ["gemini-1.5-flash", "gemini-1.5-pro", "gemini-pro"]
    if gemini_key:
        try:
            genai.configure(api_key=gemini_key)
            models = [m.name.replace('models/', '') for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
            if models: available_models = models
        except: pass
        
    # Flashã‚’å„ªå…ˆ
    default_idx = next((i for i, m in enumerate(available_models) if "flash" in m), 0)
    selected_model = st.selectbox("ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«", available_models, index=default_idx)

# --- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå®šç¾© ---
prompts = {
    "ä¼šè­°ãƒ»æ‰“ã¡åˆã‚ã›": """
    ã‚ãªãŸã¯å„ªç§€ãªæ›¸è¨˜ã§ã™ã€‚ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã¯ã€Œä¼šè­°ã€ã®éŒ²éŸ³ã§ã™ã€‚
    è¤‡æ•°ã®éŒ²éŸ³ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ™‚ç³»åˆ—ã«çµåˆã—ã¦ã„ã¾ã™ã€‚å†…å®¹ã‚’çµ±åˆã—ã€ä»¥ä¸‹ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§Markdownãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
    
    # {date} ä¼šè­°è­°äº‹éŒ²
    
    ## 1. ä¼šè­°ã®æ¦‚è¦
    ï¼ˆ3è¡Œç¨‹åº¦ã§è¦ç´„ï¼‰
    
    ## 2. æ±ºå®šäº‹é …
    - 
    
    ## 3. è­°è«–ã®å†…å®¹ï¼ˆè©³ç´°ï¼‰
    - 
    
    ## 4. ãƒã‚¯ã‚¹ãƒˆã‚¢ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆToDoï¼‰
    - [æ‹…å½“] æœŸé™: ã‚¿ã‚¹ã‚¯å†…å®¹
    """,
    
    "è¬›æ¼”ä¼šãƒ»ã‚»ãƒŸãƒŠãƒ¼": """
    ã‚ãªãŸã¯å„ªç§€ãªãƒ©ã‚¤ã‚¿ãƒ¼ã§ã™ã€‚ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã¯ã€Œè¬›æ¼”ä¼šã€ã®éŒ²éŸ³ã§ã™ã€‚
    èãæ‰‹ãŒå†…å®¹ã‚’æ·±ãç†è§£ã§ãã‚‹ã‚ˆã†ã€ä»¥ä¸‹ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§è¬›ç¾©éŒ²ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
    
    # {date} è¬›æ¼”ãƒ¬ãƒãƒ¼ãƒˆ
    
    ## 1. è¬›æ¼”ã®ãƒ†ãƒ¼ãƒã¨è¦æ—¨
    
    ## 2. ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆï¼ˆå­¦ã³ï¼‰
    - **ãƒã‚¤ãƒ³ãƒˆ1**: è©³ç´°...
    - **ãƒã‚¤ãƒ³ãƒˆ2**: è©³ç´°...
    
    ## 3. è¬›ç¾©ã®è©³ç´°æ§‹æˆï¼ˆãƒã‚¤ãƒ³ãƒ‰ãƒãƒƒãƒ—é¢¨ï¼‰
    
    ## 4. è³ªç–‘å¿œç­”ã®è¦ç‚¹
    """,
    
    "ç›¸è«‡ä¼šãƒ»ãƒ’ã‚¢ãƒªãƒ³ã‚°": """
    ã‚ãªãŸã¯è¡Œæ”¿æ›¸å£«ãªã©ã®å°‚é–€å®¶ã®ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã¯ã€Œç›¸è«‡ä¼šã€ã®éŒ²éŸ³ã§ã™ã€‚
    ç›¸è«‡è€…ã®æ‚©ã¿ã¨ã€ãã‚Œã«å¯¾ã™ã‚‹å›ç­”ã‚’æ•´ç†ã—ã¦ãã ã•ã„ã€‚
    
    # {date} ç›¸è«‡è¨˜éŒ²
    
    ## 1. ç›¸è«‡è€…ã®å±æ€§ãƒ»çŠ¶æ³
    
    ## 2. ç›¸è«‡å†…å®¹ï¼ˆæ‚©ã¿ãƒ»èª²é¡Œï¼‰
    
    ## 3. å°‚é–€å®¶ã‹ã‚‰ã®å›ç­”ãƒ»ã‚¢ãƒ‰ãƒã‚¤ã‚¹
    
    ## 4. ä»Šå¾Œã®å¯¾å¿œæ–¹é‡ãƒ»æ‰‹ç¶šã
    """
}

# --- ãƒ¡ã‚¤ãƒ³å‡¦ç† ---
uploaded_files = st.file_uploader(
    "éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆè‡ªå‹•ã§ãƒ•ã‚¡ã‚¤ãƒ«åé †ã«ä¸¦ã³æ›¿ãˆã¾ã™ï¼‰", 
    type=["mp3", "m4a", "wav"], 
    accept_multiple_files=True
)

if uploaded_files and openai_key and gemini_key:
    # ã€é‡è¦ã€‘ãƒ•ã‚¡ã‚¤ãƒ«åã§ã‚½ãƒ¼ãƒˆã™ã‚‹ã“ã¨ã§ã€Œæ™‚ç³»åˆ—é †ã€ã‚’æ‹…ä¿ã™ã‚‹
    # ä¾‹: 2026-02-03 13_00.mp3 -> 2026-02-03 13_30.mp3 ã®é †ã«ãªã‚‹
    uploaded_files.sort(key=lambda x: x.name)
    
    st.success(f"ğŸ“‚ ä»¥ä¸‹ã®é †åºã§çµåˆã—ã¦å‡¦ç†ã—ã¾ã™ï¼ˆå…¨ {len(uploaded_files)} ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰")
    
    # å‡¦ç†é †åºã‚’ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ç¢ºèªã•ã›ã‚‹è¡¨ç¤º
    order_text = ""
    for i, f in enumerate(uploaded_files):
        order_text += f"{i+1}. {f.name}\n"
    st.code(order_text, language=None)
    
    if st.button("ğŸš€ ãƒ¬ãƒãƒ¼ãƒˆä½œæˆã‚’é–‹å§‹"):
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        client = OpenAI(api_key=openai_key)
        genai.configure(api_key=gemini_key)
        model = genai.GenerativeModel(selected_model)
        
        full_transcript = ""
        
        # 1. ã™ã¹ã¦ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ–‡å­—èµ·ã“ã—ã—ã¦çµåˆ
        for i, uploaded_file in enumerate(uploaded_files):
            try:
                status_text.text(f"æ–‡å­—èµ·ã“ã—ä¸­ ({i+1}/{len(uploaded_files)}): {uploaded_file.name}")
                
                # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†
                with tempfile.NamedTemporaryFile(delete=False, suffix=f".{uploaded_file.name.split('.')[-1]}") as tmp_file:
                    tmp_file.write(uploaded_file.getvalue())
                    tmp_file_path = tmp_file.name
                
                # æ–‡å­—èµ·ã“ã—
                with open(tmp_file_path, "rb") as audio_file:
                    transcript = client.audio.transcriptions.create(
                        model="whisper-1", 
                        file=audio_file,
                        response_format="text"
                    )
                
                os.remove(tmp_file_path)
                
                # ãƒ†ã‚­ã‚¹ãƒˆçµåˆï¼ˆãƒ•ã‚¡ã‚¤ãƒ«åã®è¦‹å‡ºã—ã‚’ã¤ã‘ã‚‹ï¼‰
                full_transcript += f"\n\n--- éŒ²éŸ³ãƒ‡ãƒ¼ã‚¿: {uploaded_file.name} ---\n\n"
                full_transcript += transcript
                
                progress_bar.progress((i + 1) / (len(uploaded_files) + 1))
                
            except Exception as e:
                st.error(f"ã‚¨ãƒ©ãƒ¼ ({uploaded_file.name}): {e}")
                st.stop()

        # 2. ã¾ã¨ã‚ã¦ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ
        status_text.text("ğŸ§  AIãŒãƒ¬ãƒãƒ¼ãƒˆã‚’åŸ·ç­†ä¸­...")
        
        today_str = datetime.date.today().strftime('%Y-%m-%d')
        prompt_template = prompts[report_type].format(date=today_str)
        
        final_prompt = f"""
        {prompt_template}
        
        ã€ä»¥ä¸‹ã®çµåˆãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚‚ã¨ã«ä½œæˆã—ã¦ãã ã•ã„ã€‘
        {full_transcript}
        """
        
        try:
            response = model.generate_content(final_prompt)
            report_text = response.text
            
            progress_bar.progress(100)
            status_text.success("å®Œäº†ã—ã¾ã—ãŸï¼")
            
            # çµæœè¡¨ç¤º
            st.divider()
            st.subheader(f"ğŸ“Š {report_type} ãƒ¬ãƒãƒ¼ãƒˆ")
            st.markdown(report_text)
            
            # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ç”¨ãƒ•ã‚¡ã‚¤ãƒ«åç”Ÿæˆ
            # ãƒ¬ãƒãƒ¼ãƒˆã®1è¡Œç›®ï¼ˆã‚¿ã‚¤ãƒˆãƒ«ï¼‰ã‚’å–å¾—ã—ã¦ã¿ã‚‹
            file_name_candidate = "report"
            for line in report_text.split('\n'):
                if line.startswith("# "):
                    # # 2026-02-04 ä¼šè­°... -> 2026-02-04_ä¼šè­°...
                    file_name_candidate = line.replace("# ", "").strip().replace(" ", "_").replace("/", "-")
                    break
            
            if not file_name_candidate:
                file_name_candidate = f"{today_str}_report"
            
            save_name = f"{file_name_candidate}.md"
            
            st.download_button(
                label="ğŸ’¾ ãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜ (mdãƒ•ã‚¡ã‚¤ãƒ«)",
                data=report_text,
                file_name=save_name,
                mime="text/markdown"
            )
            
            with st.expander("æ–‡å­—èµ·ã“ã—åŸæ–‡ï¼ˆçµåˆç‰ˆï¼‰ã‚’ç¢ºèªã™ã‚‹"):
                st.text_area("åŸæ–‡", full_transcript, height=200)
                
        except Exception as e:
            st.error(f"ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")

elif not (openai_key and gemini_key):
    st.warning("ğŸ‘ˆ å·¦ã®ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
