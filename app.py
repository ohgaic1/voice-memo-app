import streamlit as st
import os
import tempfile
from openai import OpenAI
import google.generativeai as genai

# ã‚¿ã‚¤ãƒˆãƒ«
st.title("ğŸ™ï¸ AIè­°äº‹éŒ² & ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ (è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«å¯¾å¿œç‰ˆ)")
st.caption("OpenAI Whisper (æ–‡å­—èµ·ã“ã—) + Gemini (è¦ç´„)")

# ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š
with st.sidebar:
    st.header("ğŸ”‘ è¨­å®š")
    openai_key = st.text_input("OpenAI API Key (sk-...)", type="password")
    gemini_key = st.text_input("Gemini API Key (AIza...)", type="password")
    st.divider()
    st.info("â€»OpenAI APIã«ã¯ã€Œ1ãƒ•ã‚¡ã‚¤ãƒ«25MBã¾ã§ã€ã®åˆ¶é™ãŒã‚ã‚Šã¾ã™ã€‚é•·æ™‚é–“ã®éŒ²éŸ³ã¯åˆ†å‰²ã™ã‚‹ã‹ã€åœ§ç¸®ã—ã¦ãã ã•ã„ã€‚")

# è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚’æœ‰åŠ¹åŒ– (accept_multiple_files=True)
uploaded_files = st.file_uploader(
    "éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ (mp3, m4a, wav)", 
    type=["mp3", "m4a", "wav"], 
    accept_multiple_files=True
)

if uploaded_files and openai_key and gemini_key:
    st.success(f"{len(uploaded_files)} ä»¶ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¾ã—ãŸã€‚")
    
    if st.button("ğŸš€ ä¸€æ‹¬å‡¦ç†ã‚’é–‹å§‹"):
        # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã®æº–å‚™
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        # APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®æº–å‚™
        client = OpenAI(api_key=openai_key)
        genai.configure(api_key=gemini_key)
        model = genai.GenerativeModel('gemini-1.5-flash')

        # 1ã¤ãšã¤ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†
        for i, uploaded_file in enumerate(uploaded_files):
            try:
                current_file_name = uploaded_file.name
                status_text.text(f"å‡¦ç†ä¸­ ({i+1}/{len(uploaded_files)}): {current_file_name}")
                
                # --- 25MBåˆ¶é™ã®ãƒã‚§ãƒƒã‚¯ ---
                file_size_mb = uploaded_file.size / (1024 * 1024)
                if file_size_mb > 25:
                    st.error(f"âŒ ã‚¨ãƒ©ãƒ¼: {current_file_name} ã¯ {file_size_mb:.1f}MB ã‚ã‚Šã€OpenAIã®åˆ¶é™(25MB)ã‚’è¶…ãˆã¦ã„ã¾ã™ã€‚åœ§ç¸®ã™ã‚‹ã‹åˆ†å‰²ã—ã¦ãã ã•ã„ã€‚")
                    continue

                # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
                with tempfile.NamedTemporaryFile(delete=False, suffix=f".{current_file_name.split('.')[-1]}") as tmp_file:
                    tmp_file.write(uploaded_file.getvalue())
                    tmp_file_path = tmp_file.name

                # --- æ–‡å­—èµ·ã“ã— (Whisper) ---
                with open(tmp_file_path, "rb") as audio_file:
                    transcript = client.audio.transcriptions.create(
                        model="whisper-1", 
                        file=audio_file,
                        response_format="text"
                    )
                
                # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
                os.remove(tmp_file_path)

                # --- è¦ç´„ (Gemini) ---
                prompt = f"""
                ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã¯ã€Œ{current_file_name}ã€ã®éŸ³å£°æ–‡å­—èµ·ã“ã—ã§ã™ã€‚
                ãƒ“ã‚¸ãƒã‚¹ãƒ¬ãƒãƒ¼ãƒˆå½¢å¼ï¼ˆã‚¿ã‚¤ãƒˆãƒ«ã€è¦ç´„ã€ToDoï¼‰ã§ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚
                
                ãƒ†ã‚­ã‚¹ãƒˆ:
                {transcript}
                """
                response = model.generate_content(prompt)

                # --- çµæœè¡¨ç¤º ---
                with st.expander(f"âœ… {current_file_name} ã®ãƒ¬ãƒãƒ¼ãƒˆ", expanded=True):
                    st.markdown(response.text)
                    st.divider()
                    st.caption("æ–‡å­—èµ·ã“ã—åŸæ–‡")
                    st.text_area("åŸæ–‡", transcript, height=150, key=f"text_{i}")

            except Exception as e:
                st.error(f"âš ï¸ {current_file_name} ã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            
            # é€²æ—ãƒãƒ¼æ›´æ–°
            progress_bar.progress((i + 1) / len(uploaded_files))
        
        status_text.text("ã™ã¹ã¦ã®å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸï¼")

elif not (openai_key and gemini_key):
    st.warning("ğŸ‘ˆ å·¦ã®ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")

