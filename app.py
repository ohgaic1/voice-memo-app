import streamlit as st
import os
import tempfile
from openai import OpenAI
import google.generativeai as genai

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(page_title="AIè­°äº‹éŒ²ã‚¢ãƒ—ãƒª", page_icon="ğŸ™ï¸")

st.title("ğŸ™ï¸ AIè­°äº‹éŒ² & ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ")
st.caption("æœ€æ–°ã®AIãƒ¢ãƒ‡ãƒ«ã‚’è‡ªå‹•æ¤œå‡ºã—ã¦ä½¿ç”¨ã—ã¾ã™")

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼šè¨­å®š ---
with st.sidebar:
    st.header("ğŸ”‘ APIã‚­ãƒ¼è¨­å®š")
    openai_key = st.text_input("OpenAI API Key (sk-...)", type="password")
    gemini_key = st.text_input("Gemini API Key (AIza...)", type="password")
    
    st.divider()
    
    # ãƒ¢ãƒ‡ãƒ«é¸æŠæ©Ÿèƒ½ï¼ˆã‚­ãƒ¼ãŒã‚ã‚‹å ´åˆã®ã¿ãƒªã‚¹ãƒˆã‚’å–å¾—ï¼‰
    available_models = []
    if gemini_key:
        try:
            genai.configure(api_key=gemini_key)
            # ä½¿ãˆã‚‹ãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã‚’å–å¾—
            for m in genai.list_models():
                if 'generateContent' in m.supported_generation_methods:
                    # ãƒ¢ãƒ‡ãƒ«åã‹ã‚‰ 'models/' ã‚’å–ã‚Šé™¤ã
                    name = m.name.replace('models/', '')
                    available_models.append(name)
        except Exception as e:
            st.error(f"Geminiã‚­ãƒ¼ã®ã‚¨ãƒ©ãƒ¼: {e}")

    # ãƒªã‚¹ãƒˆãŒç©ºãªã‚‰ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’è¡¨ç¤º
    if not available_models:
        available_models = ["gemini-1.5-flash", "gemini-1.5-pro", "gemini-pro"]
    
    st.header("âš™ï¸ ãƒ¢ãƒ‡ãƒ«é¸æŠ")
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ gemini-1.5-flash ã‚’å„ªå…ˆçš„ã«é¸ã¶
    default_index = 0
    for i, m in enumerate(available_models):
        if "flash" in m:
            default_index = i
            break
            
    selected_model = st.selectbox("ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«", available_models, index=default_index)
    st.caption(f"é¸æŠä¸­: {selected_model}")

# --- ãƒ¡ã‚¤ãƒ³å‡¦ç† ---
uploaded_files = st.file_uploader(
    "éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", 
    type=["mp3", "m4a", "wav"], 
    accept_multiple_files=True
)

if uploaded_files and openai_key and gemini_key:
    st.success(f"æº–å‚™å®Œäº†ï¼ ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {selected_model}")
    
    if st.button("ğŸš€ ä¸€æ‹¬å‡¦ç†ã‚’é–‹å§‹"):
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        # APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆæº–å‚™
        client = OpenAI(api_key=openai_key)
        genai.configure(api_key=gemini_key)
        model = genai.GenerativeModel(selected_model) # é¸æŠã—ãŸãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨

        for i, uploaded_file in enumerate(uploaded_files):
            try:
                current_name = uploaded_file.name
                status_text.text(f"â–¶ å‡¦ç†ä¸­: {current_name}")
                
                # 1. éŸ³å£°å‡¦ç† (Whisper)
                # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
                with tempfile.NamedTemporaryFile(delete=False, suffix=f".{current_name.split('.')[-1]}") as tmp_file:
                    tmp_file.write(uploaded_file.getvalue())
                    tmp_file_path = tmp_file.name
                
                # 25MBãƒã‚§ãƒƒã‚¯
                if os.path.getsize(tmp_file_path) > 25 * 1024 * 1024:
                    st.error(f"âŒ {current_name} ã¯ã‚µã‚¤ã‚ºãŒå¤§ãã™ãã¾ã™(25MBè¶…)ã€‚")
                    os.remove(tmp_file_path)
                    continue

                # æ–‡å­—èµ·ã“ã—å®Ÿè¡Œ
                with open(tmp_file_path, "rb") as audio_file:
                    transcript = client.audio.transcriptions.create(
                        model="whisper-1", 
                        file=audio_file,
                        response_format="text"
                    )
                os.remove(tmp_file_path)

                # 2. è¦ç´„å‡¦ç† (Gemini)
                prompt = f"""
                ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã¯ä¼šè­°ã®éŒ²éŸ³ã§ã™ã€‚
                å†…å®¹ã‚’æ•´ç†ã—ã€ãƒ“ã‚¸ãƒã‚¹ãƒ¬ãƒãƒ¼ãƒˆå½¢å¼ï¼ˆã‚¿ã‚¤ãƒˆãƒ«ã€è¦ç´„ã€ToDoï¼‰ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
                
                ãƒ†ã‚­ã‚¹ãƒˆ:
                {transcript}
                """
                
                response = model.generate_content(prompt)

                # çµæœè¡¨ç¤º
                with st.expander(f"âœ… ãƒ¬ãƒãƒ¼ãƒˆ: {current_name}", expanded=True):
                    st.markdown(response.text)
                    st.divider()
                    st.text_area("æ–‡å­—èµ·ã“ã—åŸæ–‡", transcript, height=100)

            except Exception as e:
                st.error(f"âš ï¸ ã‚¨ãƒ©ãƒ¼ ({current_name}): {e}")
            
            progress_bar.progress((i + 1) / len(uploaded_files))
        
        status_text.success("ã™ã¹ã¦ã®å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸï¼")

elif not (openai_key and gemini_key):
    st.warning("ğŸ‘ˆ å·¦ã®ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
